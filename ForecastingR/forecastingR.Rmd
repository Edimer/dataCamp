---
title: "Forecasting in R"
subtitle: "Curso DataCamp - Rob Hyndman"
author: "Edimer David Jaramillo"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    css: estilo.css
    theme: paper
    highlight: breezedark
    code_folding: hide
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE,
                      fig.align = "center",
                      fig.width = 9)
```

<center>
<img src = "img/img1.png" />
</center>

# Contenido del curso

1. Explorando y visualizando series de tiempo en R.
2. Métodos de referencia y precisión en *forecast*.
3. Suavizamiento exponencial.
4. Forecasting con modelos ARIMA.
5. Métodos avanzados en *forecast*.

# Libro guía

- [Forecasting: Principles and Practice.](https://otexts.com/fpp3/)

<center>
<img src = "img/img2.png" />
</center>

# Explorando y visualizando series de tiempo en R

## Consideraciones iniciales

- En R todos los datos de tipo *times series* serán manejados a través de la clase `ts`.
- Las series de tiempo pueden ser **regularmente espaciadas** si están registradas en intervalos de tiempo iguales, por ejemplo, cada día, semana, mes, etc.
- Es de vital importancia evidenciar comportamientos específicos de las series temporales, tales como la **tendencia**, **estacionalidad** y **ciclicidad**.
- El objetivo fundamental del forecasting es proporcionar herramientas matemáticas válidas para hacer predicciones del futuro con base en patrones de comportamiento históricos.
- Las predicciones en general tienen asociado grados de incertidumbre, los cuales pueden ser estudiados a través de los intervalos de predicción, cuya característica principal es que cuanto más largo sea el período de pronóstico, más amplios serán los intervalos.

## Función `autoplot()`

```{r}
library(forecast)

# Autoplot con facetas
autoplot(gold, facets = TRUE)

# Autoplot sin facetas
#$autoplot(gold, facets = FALSE)
```

- Con la función `frequency()` es posible conocer la frecuencia de la serie de tiempo bajo análisis. Por ejemplo, la frecuencia de `gold` es anual, ya que es igual a 1.

```{r}
frequency(gold)
```

## Función `ggseasonplot()`

- Esta función permite visualizar patrones de comportamiento respecto a las "estaciones" sobre las cuales es medida la serie temporal.

```{r, fig.width=9}
library(fpp2)
library(ggpubr)

ggarrange(
  autoplot(a10),
  ggseasonplot(a10),
  ncol = 2
)
```

- Este gráfico puede ser obtenido en términos de coordenadas polares.

```{r}
ggseasonplot(a10, polar = TRUE)
```

## Función `ggsubseriesplot()`

- Esta función permite obtener mini-diagramas para cada estación, además de graficar la línea de tendencia promedio de cada trama.

```{r, fig.width=9}
ggarrange(
  autoplot(beer),
  ggsubseriesplot(beer),
  ncol = 2
)

```

- La función `window()` permite extraer subconjuntos de datos de un objeto tipo `ts`

```{r, fig.width=9}
mywindow <- window(ausbeer, start = 1992)
ggarrange(
  autoplot(mywindow),
  ggsubseriesplot(mywindow),
  ncol = 2
)
```

## Patrones en series de tiempo

<center>
<img src = "img/img3.png" />
</center>

- **Tendencia:** cuando existe aumento o disminución a través del tiempo.
- **Estacionalidad:** ocurre cuando hay un patrón regular en las series de tiempo relacionadas con el calendario, por ejemplo, patrones anuales, mesuales o semanales. Los patrones estacionales siempre poseen la misma longitud de tiempo.
- **Ciclicidad:** ocurre cuando hay incrementos o disminuciones que no están ligadas al calendario, es decir, que no pertenecen a un período fijo.

<center>
<img src = "img/img4.png" />
</center>

- Diferencias entre **estacionalidad y ciclicidad:**
    - Los patrones estacionales tienen longitud constante.
    - Los patrones ciclícos tienen longitud variable.
    - Si aparecen juntos en una misma serie temporal, la longitud del patrón ciclíco será siempre mayor que la longitud del patrón estacional.
    - La longitud de patrones ciclícos tiende a ser más variable que la longitud de patrones estacionales.
    - Es mucho más difícil predecir patrones ciclícos que patrones estacionales.
    
## Autocorrelación de series no estacionales

### Función `ggLagplot()`

- El diagrama de rezagos permite evidenciar la relación de la observación en el tiempo *t* con *t-1*, *t-2*...*t-n*.

```{r}
gglagplot(oil)
```

### Función `ggAcf()`

- La correlación asociada con los rezagos se denomina *función de autocorrelación (ACF)*. La función `ggAcf()` permite graficar las autocorrelaciones. Las líneas que se salen de las horizontales punteadas de color azul, tienen una relación estadísticamente significativa con la observación *t*.

```{r}
ggAcf(oil)
```

## Ruido Blanco (*white noise*)

- El ruido blanco como se conoce en series de tiempo, es análogo a las **variables aleatorias independientes e idénticamente distribuidas (iid)** que se abordan en el análisis estadístico.
- En este tipo de datos no sucede nada, no hay tendencia, no hay estacionalidad, no hay ciclicidad y tampoco existe autocorrelación.
- Es totalmente aleatorio.
- El ruido blanco se constituye como la base de muchos modelos de pronósticos.
- El ruido blanco es una serie temporal puramente aleatoria.

### Simulando ruido blanco

```{r}
set.seed(3)
mywn <- ts(rnorm(36))
autoplot(mywn)
```

### Autocorrelación de ruido blanco

- Como es de esperar, ninguna línea supera las punteadas azules. Por ser ruido blanco no se presenta autocorrelación.
- Las líneas azules se basan en la distribución de la autocorrelación, suponiendo que los datos son ruido blanco (hipótesis nula).
- Picos dentro de las líneas azules pueden ser ignorados, sin embargo, aquellos que queden por fuera podrían ser indicativos de patrones interesantes en los datos, sugiriendo que como mínimo hay ciertos comportamientos que podrían ser de utilidad para la construcción de modelos de pronóstico.

```{r}
ggAcf(mywn)
```

### Pruba [Ljung-Box](https://es.wikipedia.org/wiki/Prueba_de_Ljung-Box)

- Esta prueba permite contrastar si la serie temporal es ruido blanco o no. Esto se hace bajo el siguiente juego de hipótesis:

$$H_0: La\ serie\ es\ ruido\ blanco\\
H_1: La\ serie\ no\ es\ ruido\ blanco$$

- Un valor p significativo indicará que existe evidencia para suponer que la serie temporal **no es ruido blanco**.

```{r}
Box.test(mywn)
```

- Como era de esperar la prueba arroja un valor p de 0.9406 para los datos simulados como ruido blanco, ya que éstos en efecto son aleatorios. 
- Es posible aplicar la misma prueba con valores diferentes de rezago (por defecto es 15). Además, es posible diferenciar la serie (`diff()`) y aplicar la prueba.

```{r}
ggAcf(diff(goog))
Box.test(diff(goog), lag = 10, type =  "Ljung")
```

# Métodos de referencia y precisión en *forecast*

## Intervalos de predicción

<center>
<img src = "img/img5.png" /> <img src = "img/img6.png" />
</center>

## Pronóstico Naive (*"ingenuo"*)

- Método de pronóstico simple.
- Utiliza como pronóstico la observación más reciente.
- En R se pueden usar las funciones `naive()` y `snaive()`, para series no estacionales y estacionales, respectivamente. 

```{r}
# Simulando datos autoregresivos de orden 1
set.seed(1)
my_serie <- arima.sim(model = list(ar = 0.9), n = 24, mean = 600, sd = 48)

# Naive
my_naive <- naive(y = my_serie, h = 6)
autoplot(my_naive)
```

- **Ejemplo de datos estacionales con `snaive()`:**

```{r}
library(fpp2) # data ausbeer
my_snaive <- snaive(y = ausbeer, h = 10)
autoplot(my_snaive)
```

## Residuales

- Suposiciones
    - **Esenciales:**
        - Errores incorrelacionados.
        - Errorres con media cero
    - **No esenciales:**
        - Errores con varianza constante (homocedasticidad)
        - Errores con distribución normal
- De no satisfacer los supuestos esenciales, nuestro modelo carece de poder predictivo, indicando que aún hay información contenida en los datos que puede ser explicada con otra alternativa de modelación.
- Si el modelo no cumple los no esenciales se compromete la validez de los intervalos de predicción, no obstante, la estimación puntual sigue siendo válida.
- El *ruido blanco* satisface las tres primeras suposiciones, cuando se cumplen las cuatro a este se le conoce como *ruido blanco gaussiano*.
- La función `checkresiduals()` de la biblitoeca `forecast` permite analizar los residuales de manera fácil.

### Ajustado vs Predicho

```{r}
fc <- naive(oil)
autoplot(oil, series = "Data") + xlab("Year") +
autolayer(fitted(fc), series = "Fitted")
```

### Analisis de residuales

- **Satisface supuestos:**

```{r}
goog %>% naive() %>% checkresiduals()
```

- **No satisface supuestos:**

```{r}
ausbeer %>% snaive() %>% checkresiduals()
```

## Train - Test

<center>
<img src = "img/img7.png" />
</center>

- Validar nuestro modelo con los mismos datos que fue entrenado podría conducir al *sobreajuste*.
- Como elemento de validación es posible particionar la serie en *train* y *test*. Con los datos de *train* se ajusta el modelo y con los datos de *test* se evalúa el desempeño predicitivo del modelo.

```{r}
training <- window(oil, end = 2003)
test <- window(oil, start = 2004)
fc <- naive(training, h = 10)
autoplot(fc) + autolayer(test, series = "Test data")
```

## Métricas de error

<center>
<img src = "img/img8.png" />
</center>

- El MAPE no debe ser utilizado en series con ceros (como la temperatura) "reales" o valores pequeños, como alternativa el MASE es una mejor métrica para evaluar modelos en este tipo de series.

### Función `accuracy()`

- La función `accuracy()` de la biblioteca `forecast()` permite calcular varias métricas de error.

```{r}
# Data para train
train <- subset(gold, end = 1000)

# Train Naive: model 1
naive_fc <- naive(train, h = 108)

# Train mean forecast: model 2 
mean_fc <- meanf(train, h = 108)

# Accuracy model 1 vs model 2
accuracy(naive_fc, gold)
accuracy(mean_fc, gold)
```

## Validación cruzada

# Suavizamiento Exponencial

# Forecast con ARIMA

# Métodos avazandos


