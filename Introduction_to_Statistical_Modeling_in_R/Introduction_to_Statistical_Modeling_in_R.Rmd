---
title: "Introduction to Statistical Modeling in R"
subtitle: "Curso DataCamp - Daniel Kaplan"
author: "Edimer David Jaramillo"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    css: estilo.css
    theme: journal
    highlight: pygments
    code_folding: show
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE,
                      fig.align = "center",
                      fig.width = 9)
```

<center>
<img src = "img/img1.png" />
</center>

# Contenido del curso

1. **Capítulo 1:** ¿Qué es el modelado estadístico?
2. **Capítulo 2:** Diseñar, entrenar y evaluar modelos
3. **Capítulo 3:** Evaluación del desempeño de la predicción
4. **Capítulo 4:** Explorando datos con modelos
5. **Capítulo 5:** Covariables y tamaño del efecto

# Capítulo 1

## Notas

- En todo el curso se hace uso masivo de tres tipos de objetos:
  - *Dataframes*
  - Fórmulas (`Y ~ X`)
  - Funciones (`mean`, `lm`...)
- Un modelo es una representación simple de la realidad.
- Un modelo estadístico es una representación de la realidad basado en datos.
- El modelamiento no es un resultado en sí mismo, es un proceso. La pregunta que se desea responder con el modelado debe ser clara para cumplir con el objetivo propuesto.

<center>
<img src = "img/img2.png" height = 350 />
</center>

## Biblioteca `mosaic`  
  
- La biblioteca [mosaic](https://cran.r-project.org/web/packages/mosaic/index.html) permite utilizar la notación de fórmulas para algunas funciones que R no lo permite normalmente, por ejemplo, `mean`:

```{r}
library(mosaic)
mean(Sepal.Length ~ Species, data = iris)
```

- También tiene funciones específicas para graficar con `ggplot2` a través de la notación de fórmula (empiezan con el prefijo `gf_`):

```{r}
gf_boxplot(Sepal.Length ~ Species, data = iris)
```

```{r}
gf_point(iris$Sepal.Length ~ iris$Petal.Length)
```

# Capítulo 2

## Ajuste de modelos

- Datos: `Runners`. Este conjunto de datos está disponible en la biblioteca *statisticalModeling*. Puede ser obtenido directamente desde el repositorio de Github de [Daniel Kaplan.](https://github.com/dtkaplan/statisticalModeling/blob/master/data/Runners.rda) 
- En este ejemplo se constuyen tres modelos lineales (`lm()`) y tres modelos (árboles) con particionamiento recursivo (`rpart()`):
  - $net \sim age$
  - $net \sim sex$
  - $net \sim age + sex$
  
```{r}
# Cargando datos
load("data/Runners.rda")

# Modelos
model1_lm <- lm(net ~ age, data = Runners)
model2_lm <- lm(net ~ sex, data = Runners)
model3_lm <- lm(net ~ age + sex, data = Runners)
```

- Es posible visualizar los tres modelos anteriores a través de la función `fmodel()` que está disponible en la biblioteca [statisticalModeling](https://github.com/dtkaplan/statisticalModeling):

```{r}
library(statisticalModeling)
fmodel(model1_lm)
fmodel(model2_lm)
fmodel(model3_lm)
```

- **Modelos `rpart()`:**

```{r}
# Modelos
library(rpart)
model1_rpart <- rpart(net ~ age, data = Runners)
model2_rpart <- rpart(net ~ sex, data = Runners)
model3_rpart <- rpart(net ~ age + sex, data = Runners)
model3_rpart_cp <- rpart(net ~ age + sex, cp = 0.002, data = Runners)
```

- **Visualizando modelos:**

```{r}
fmodel(model3_rpart_cp, ~ age + sex)
```

## Evaluación de modelos
  
<center>
<img src = "img/img3.png" height = 350 />
</center> 

- Se ajusta un modelo lineal con la base de datos [AARP.](https://github.com/dtkaplan/statisticalModeling/blob/master/data/AARP.rda)

```{r}
load("data/AARP.rda")
insurance_cost_model <-  lm(Cost ~ Age + Sex + Coverage, data = AARP)
```

- Predicción sobre nuevos datos:

```{r}
# Construct a data frame: example_vals 
example_vals <- data.frame(Age = 60, Sex = "F", Coverage = 200)

# Predict insurance cost using predict()
predict(object = insurance_cost_model, newdata = example_vals)

```

- Predicción utilizando la función **`evaluate_model()`** de la biblioteca `statisticalModeling`:

```{r}
evaluate_model(insurance_cost_model, example_vals)
```

- Es posible evaluar de forma gráfica los resultados del modelo:

```{r}
fmodel(insurance_cost_model, ~ Coverage + Age + Sex)
```

- Cambiando de orden las facetas y ejes:

```{r}
new_formula <- ~ Age + Sex + Coverage
fmodel(insurance_cost_model, new_formula)
```

# Capítulo 3

## Comparando dos modelos

- En este ejemplo la comparación está orientada a evaluar la importancia de incluir una variable adicional al modelo.
- En este caso se comparan dos modelos lineales (`lm`) a través del cuadrado medio del error:

$$CME = \frac{1}{n}\sum_{i=1}^{n}(y - \hat{y})^2$$

```{r}
# Datos sin NA
Runners_noNA <- na.omit(Runners)

# Modelos
mod1 <- lm(net ~ age, data = Runners_noNA)
mod2 <- lm(net ~ age + sex, data = Runners_noNA)

# Predicciones
pred_mod1 <- predict(mod1, newdata = Runners_noNA)
pred_mod2 <- predict(mod2, newdata = Runners_noNA)

# CME
mean((Runners_noNA$net - pred_mod1)^2)
mean((Runners_noNA$net - pred_mod2)^2)
```

## Training - Testing

- División de datos en entrenamiento (*training*) y prueba (*testing*) para evaluar la capacidad predictiva del modelo.
- Aunque hay funciones en algunos paquetes de R para ejecutar la división de datos de manera sistemática y rápida, en este ejemplo se opta por hacerlo manualmente.

```{r}
# Generación aleatoria de TRUE y FALSE
set.seed(2020)
Runners_noNA$training_cases <- rnorm(nrow(Runners_noNA)) > 0

# Modelo
base_model <- lm(net ~ age + sex, data = subset(Runners_noNA, training_cases))

# Evaluando el modelo en casos nuevos (testing)
Preds <- evaluate_model(base_model, data = subset(Runners_noNA, !training_cases))

# Calculate the MSE on the testing data
with(data = Preds, mean((net - model_output)^2))
```


## Validación cruzada

### Comparando errores de predicción

- En el ejemplo anterior se ejecutó validación cruzada simple, con una sola partición de entrenamiento y prueba. Es posible repetir el preceso de remuestreo y obtener el error de predicción a través de validación cruzada, luego se puede contrastar con el error de predicción ajustado con todos lo datos y a través de la prueba *t-student* determinar si son estadísticamente diferentes.
- La biblioteca *statisticalModeling* tiene consigo la función `cv_pred_error()` que permite ajustar validación cruzada más de una vez.

```{r}
# Modelo base con todos los datos
mod_base <- lm(net ~ age + sex, data = Runners_noNA)

# Evaludación del modelo
eval_mod_base <- evaluate_model(mod_base, data = Runners_noNA)
mse_mod_base <- with(eval_mod_base, mean((net - model_output)^2))
mse_mod_base
```

- **Modelo con validación cruzada:**

```{r}
error_cv <- cv_pred_error(mod_base, ntrials = 5)
error_cv
```

- **Comparando error del modelo base vs error de validación cruzada:** son estadísticamente diferentes, el intervalo de confianza del error con validación cruzada se ubica a la derecha del error del modelo base. Este resultado permite evidenciar lo "optimista" que puede llegar a ser el ajuste de un modelo predictivo con los datos completos.

```{r}
mosaic::t.test(~ mse, mu = mse_mod_base, data = error_cv)
```

### Elegir una variable para el modelo

- En este caso se va a utilzar la validación cruzada para definir si la inclusión de una nueva variable resulta siendo favorable en la capacidad predictiva del modelo.

```{r}
# Modelo con sólo edad
modelo_base <- lm(net ~ age, data = Runners_noNA)

# Modelo con edad y género
mod_dos <- lm(net ~ age + sex, data = Runners_noNA)

# Comparando con validación cruzada ambos modelos
res_modelos <- cv_pred_error(modelo_base, mod_dos, ntrials = 5)
res_modelos
```

- **Prueba *t-student* para comparación de medias (dos poblaciones):** las diferencias entre los modelos son estadísticamente significativas, siendo inferior el *MSE* del modelo dos, lo que permite afirmar que la inclusión de la variable *sex* es provechosa para la capacidad predictiva del modelo.

```{r}
mosaic::t.test(mse ~ model, data = res_modelos)
```

# Capítulo 4

## Problema de clasificación

### Predicción de variables categóricas (clasificación)

- Ejemplo de clasificación con `rpart` con la base de datos `Runners`.
- La tasa de error se calcula como el promedio de las predicciones diferentes de lo real.

```{r}
# Ajustando el modelo
mod_clas1 <- rpart(start_position ~ age + sex, cp = 0.001, data = Runners_noNA)

# Evaluando el modelo
model_output <- evaluate_model(mod_clas1, data = Runners_noNA, type = "class")

# Tasa de error
with(model_output, mean(start_position != model_output))
```

### Train - Test

- Se dividen los datos en *entrenamiento* y *prueba* con las filas asignadas previamente.
- Se ajustan tres modelos:
  - Modelo nulo 
  - Modelo con predictora *edad*
  - Modelo con predictora *edad* y *género*
- Se compara la tasa de error en el conjunto de prueba para los tres modelos. El objetivo es verificar si la inclusión de la *edad* y el *género* resulta siendo provechoso para la capacidad predictiva del modelo.
- Aunque el parámetro de complejidad (*cp*) se puede optimizar, en este caso se utiliza el valor 0.001 para todos los modelos.

```{r}
# Creando una variable con 1 en todas las filas para el modelo nulo
Runners_noNA$todos1 <- 1

# Training y testing
training_data <- subset(Runners_noNA, training_cases)
testing_data <- subset(Runners_noNA, !training_cases)

# Modelo nulo
mod_nulo <- rpart(start_position ~ todos1, data = training_data, cp = 0.001)

# Modelo edad 
mod_age <- rpart(start_position ~ age, data = training_data, cp = 0.001)

# Modelo edad y género
mod_age_sex <- rpart(start_position ~ age + sex, data = training_data, cp = 0.001)

# Predicción de modelos
output_nulo <- evaluate_model(mod_nulo, data = testing_data, type = "class")
output_age <- evaluate_model(mod_age, data = testing_data, type = "class")
output_age_sex <- evaluate_model(mod_age_sex, data = testing_data, type = "class")

# Tasa de error en testing
error_nulo <- with(output_nulo, mean(start_position != model_output))
error_age <- with(output_age, mean(start_position != model_output))
error_age_sex <- with(output_age_sex, mean(start_position != model_output))
```

- **Tasas de error:**

```{r, collapse=TRUE}
cat("Tasa de error modelo nulo:", error_nulo)

cat("Tasa de error modelo con edad:", error_age)

cat("Tasa de error modelo con edad y género:", error_age_sex)
```

## Explorando relaciones de variables

- **Datos de ejemplo:** encuesta de salud y nutrición `NHANES` (*National Health and Nutrition Evaluation Survey*) (consultar ayuda de la base de datos `?NHANES`). La base de datos tiene 10 mil filas y 76 columnas.

```{r}
# 
library(NHANES)
library(dplyr)

# Primeras 20 variables
names(NHANES) %>% head(20)
```

- Se construye un modelo inicial con la configuración por defecto de la función `rpart`, donde la variable respuesta es el hábito de fumar. Solo se modela en función de algunas variables del total de la base de datos. La función `prp` permite graficar un árbol de decisión bajo partición recursiva.

```{r}
library(rpart.plot)
model <- rpart(SmokeNow ~ Poverty + MaritalStatus +
                 Gender + BMI + TotChol + AgeFirstMarij,
               data = NHANES)
prp(model, type = 4, extra = 105, varlen = 0)
```

- Al aumentar la complejida del modelo a través del parámetro **`cp`** es posible obtener un árbol con mayor número de ramificaciones. Elegir entre uno u otro es posible con la medición del error en *test*.

```{r, fig.width=9}
model_complex <- rpart(SmokeNow ~ Poverty + MaritalStatus
                       + Gender + BMI + TotChol + AgeFirstMarij,
                       data = NHANES, cp = 0.007)
prp(model_complex, type = 4, extra = 105, varlen = 0)
```

- **Otro ejemplo:** variables asociadas con bajo peso al nacer (base de datos `Birth_weight`).

```{r}
model_1 <- rpart(baby_wt ~ smoke + income, 
                 data = Birth_weight)
model_2 <- rpart(baby_wt ~ mother_age + mother_wt, 
                 data = Birth_weight)

prp(model_1, type = 3)
```

- Un modelo con más variablres predictoras:

```{r}
model_3 <- rpart(baby_wt ~ mother_age + mother_wt + smoke + income, 
                 data = Birth_weight)

prp(model_3, type = 3)
```

- Un modelo con todas las variables:


```{r}
model_4 <- rpart(baby_wt ~ ., data = Birth_weight)

prp(model_4, type = 3)
```

- Un modelo para explicar la relación del tabaquismo con el período de gestación. Esta nomenclatura en la fórmula significa que la gestación es explicada por todas las variables excepto el peso del bebé.

```{r, fig.width=9}
model_5 <- rpart(gestation ~ . - baby_wt, data = Birth_weight)

prp(model_5, type = 3)
```

# Capítulo 5

## Covariables

### Precios de casas

- Variables explicativas que no son de interés directo, sin embargo, juegan un papel fundamental en el sistema bajo análisis.
- En este ejemplo se utiliza la base de datos `Houses_for_sale`.

```{r}
# Train the model price ~ fireplaces
simple_model <- lm(price ~ fireplaces, data = Houses_for_sale)

# Evaluate simple_model
evaluate_model(simple_model)
```

- La diferencia de precio de una casa con chimenea respecto a una que no la tiene, asumiendo el modelo anterior, sería la siguiente:

```{r}
238522.7 - 171823.9	
```


- Otro modelo con una variable adicional:

```{r}
# Train another model including living_area
sophisticated_model <- lm(price ~ fireplaces + living_area,
                          data = Houses_for_sale)

# Evaluate that model
evaluate_model(sophisticated_model)
```

- Manteniendo constante la variable `living_area`, por ejemplo, en `2000`, se calcula nuevamente la diferencia de precio de una casa con chimenea y una que no la tiene. Ahora las diferencias son mucho menores, lo que sugiere que la variable `living_area` juega un papel importante en el modejo construido.

```{r}
242319.5 - 233357.1
```

## Crímenes USA 1960

- Dos modelos con variables independientes:

```{r}
# Train model_1 and model_2
model_1 <- lm(R ~ X, data = Crime)
model_2 <- lm(R ~ W, data = Crime)

# Evaluate each model...
evaluate_model(model_1)
evaluate_model(model_2)
```

- Calculando diferencias para dos niveles de cada variable (en cada modelo):

```{r}
change_with_X <- 106.82223 - 89.46721
change_with_W <- 103.70777 - 68.32909
```

- Modelo con las dos variables:

```{r}
# Train model_3 using both X and W as explanatory variables
model_3 <- lm(R ~ X + W, data = Crime)

# Train model_3 using both X and W as explanatory variables
model_3 <- lm(R ~ X + W, data = Crime)

# Evaluate model_3
evaluate_model(model_3)
```

- Calculando diferencias para los  mismos dos niveles pero manteniendo constante valores de la otra covariable. Los resultados son muy diferentes al considerar las dos variables en el mismo modelo.

```{r}
change_with_X_holding_W_constant <- 134.86434 - 41.22502
change_with_W_holding_X_constant <- 134.86434 - 31.03422
```

## Salarios

- El ejemplo está enfocado a verificar las diferencias salariales entre hombres y mujeres. La base de datos utilizada es `Trucking_jobs`. Actúan como covariables `age` (edad), `hiredyears` (años de contratación) y `title` (puesto de trabajo).

```{r}
model_1 <- lm(earnings ~ sex, data = Trucking_jobs)
model_2 <- lm(earnings ~ sex + age, data = Trucking_jobs)
model_3 <- lm(earnings ~ sex + hiredyears, data = Trucking_jobs)
model_4 <- lm(earnings ~ sex + title, data = Trucking_jobs)
model_5 <- lm(earnings ~ sex + age + hiredyears + title, data = Trucking_jobs)
```

- Evaluando los modelos con un valor fijo para las covariables:

```{r}
evaluate_model(model_1)
evaluate_model(model_2, age = 45)
evaluate_model(model_3, hiredyears = 3)
evaluate_model(model_4, title = "PROGRAMMER")
evaluate_model(model_5, age = 45, hiredyears = 3,
               title = "PROGRAMMER")
```

## Tamaño del efecto

- El tamaño del efecto es una propiedad del modelo mas no de los datos en sí mismos.
- Para variables cuantitativas puede ser proporcionado como una tasa y para variables categóricas como una diferencia.
